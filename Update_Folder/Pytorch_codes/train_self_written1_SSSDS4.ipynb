{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Menm5Qpj6nsX2Ogpz1lp2YEBQjk4yR0l","authorship_tag":"ABX9TyMGEZvEbu3vnWOOvHLlvss3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["# 我们要定位文件位置，使用这里的代码，具体要将此notebook文件和function文件（或文件夹）放在同一个文件夹路径下，具体路径是什么可以左侧找到目标文件夹然后右击复制文件夹路径来获得\n","import sys\n","sys.path.insert(0,'/content/drive/MyDrive/JPMorgan/自写代码/Pytorch_codes')"],"metadata":{"id":"P8-ZYy5QY9yH","executionInfo":{"status":"ok","timestamp":1668879141464,"user_tz":0,"elapsed":2,"user":{"displayName":"Zihao LIU","userId":"01384449044500819690"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["pip install einops"],"metadata":{"id":"OwvisHXMxdXn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install wandb"],"metadata":{"id":"cYSzyUAFxj31"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install pytorch_lightning"],"metadata":{"id":"tTBC0A48xuEG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install pykeops"],"metadata":{"id":"ow6HdCihL2Tu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYr-Y-SV56wl","executionInfo":{"status":"ok","timestamp":1668797568441,"user_tz":0,"elapsed":8129,"user":{"displayName":"Zihao LIU","userId":"01384449044500819690"}},"outputId":"da5ed9e8-0cb9-4693-b13f-27aaf46674d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","import argparse\n","import json\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","from utils.util import find_max_epoch, print_size, training_loss, calc_diffusion_hyperparams\n","from utils.util import get_mask_mnr, get_mask_bm, get_mask_rm\n","\n","from imputers.DiffWaveImputer import DiffWaveImputer\n","from imputers.SSSDSAImputer import SSSDSAImputer\n","from imputers.SSSDS4Imputer import SSSDS4Imputer\n","\n","import easydict"],"metadata":{"id":"E3vheVLoZmn8","executionInfo":{"status":"ok","timestamp":1668879358084,"user_tz":0,"elapsed":186,"user":{"displayName":"Zihao LIU","userId":"01384449044500819690"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def train(output_directory,\n","          ckpt_iter,\n","          n_iters,\n","          iters_per_ckpt,\n","          iters_per_logging,\n","          learning_rate,\n","          use_model,\n","          only_generate_missing,\n","          masking,\n","          missing_k):\n","    \n","    \"\"\"\n","    Train Diffusion Models\n","\n","    Parameters:\n","    output_directory (str):         save model checkpoints to this path\n","    ckpt_iter (int or 'max'):       the pretrained checkpoint to be loaded; \n","                                    automatically selects the maximum iteration if 'max' is selected\n","    data_path (str):                path to dataset, numpy array.\n","    n_iters (int):                  number of iterations to train\n","    iters_per_ckpt (int):           number of iterations to save checkpoint, \n","                                    default is 10k, for models with residual_channel=64 this number can be larger\n","    iters_per_logging (int):        number of iterations to save training log and compute validation loss, default is 100\n","    learning_rate (float):          learning rate\n","\n","    use_model (int):                0:DiffWave. 1:SSSDSA. 2:SSSDS4.\n","    only_generate_missing (int):    0:all sample diffusion.  1:only apply diffusion to missing portions of the signal\n","    masking(str):                   'mnr': missing not at random, 'bm': blackout missing, 'rm': random missing\n","    missing_k (int):                k missing time steps for each feature across the sample length.\n","    \"\"\"\n","\n","    # generate experiment (local) path\n","    local_path = \"T{}_beta0{}_betaT{}\".format(diffusion_config[\"T\"],\n","                                              diffusion_config[\"beta_0\"],\n","                                              diffusion_config[\"beta_T\"])\n","\n","    # Get shared output_directory ready\n","    output_directory = os.path.join(output_directory, local_path)\n","    if not os.path.isdir(output_directory):\n","        os.makedirs(output_directory)\n","        os.chmod(output_directory, 0o775)\n","    print(\"output directory\", output_directory, flush=True)\n","\n","    # map diffusion hyperparameters to gpu\n","    for key in diffusion_hyperparams:\n","        if key != \"T\":\n","            diffusion_hyperparams[key] = diffusion_hyperparams[key].cuda()\n","\n","    # predefine model\n","    if use_model == 0:\n","        net = DiffWaveImputer(**model_config).cuda()\n","    elif use_model == 1:\n","        net = SSSDSAImputer(**model_config).cuda()\n","    elif use_model == 2:\n","        net = SSSDS4Imputer(**model_config).cuda()\n","    else:\n","        print('Model chosen not available.')\n","    print_size(net)\n","\n","    # define optimizer\n","    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n","\n","    # load checkpoint\n","    if ckpt_iter == 'max':\n","        ckpt_iter = find_max_epoch(output_directory)\n","    if ckpt_iter >= 0:\n","        try:\n","            # load checkpoint file\n","            model_path = os.path.join(output_directory, '{}.pkl'.format(ckpt_iter))\n","            checkpoint = torch.load(model_path, map_location='cpu')\n","\n","            # feed model dict and optimizer state\n","            net.load_state_dict(checkpoint['model_state_dict'])\n","            if 'optimizer_state_dict' in checkpoint:\n","                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","            print('Successfully loaded model at iteration {}'.format(ckpt_iter))\n","        except:\n","            ckpt_iter = -1\n","            print('No valid checkpoint model found, start training from initialization try.')\n","    else:\n","        ckpt_iter = -1\n","        print('No valid checkpoint model found, start training from initialization.')\n","\n","        \n","        \n","    \n","    ### Custom data loading and reshaping ###\n","        \n","        \n","\n","    training_data = np.load(trainset_config['train_data_path'])  # 'train_data_path'\n","    training_data = np.split(training_data, 160, 0)\n","    training_data = np.array(training_data)\n","    training_data = torch.from_numpy(training_data).float().cuda()\n","    print('Data loaded')\n","\n","    # training\n","    n_iter = ckpt_iter + 1\n","    while n_iter < n_iters + 1:\n","        for batch in training_data:\n","\n","            if masking == 'rm':\n","                transposed_mask = get_mask_rm(batch[0], missing_k)\n","            elif masking == 'mnr':\n","                transposed_mask = get_mask_mnr(batch[0], missing_k)\n","            elif masking == 'bm':\n","                transposed_mask = get_mask_bm(batch[0], missing_k)\n","\n","            mask = transposed_mask.permute(1, 0)\n","            mask = mask.repeat(batch.size()[0], 1, 1).float().cuda()\n","            loss_mask = ~mask.bool()\n","            batch = batch.permute(0, 2, 1)\n","\n","            assert batch.size() == mask.size() == loss_mask.size()\n","\n","            # back-propagation\n","            optimizer.zero_grad()\n","            X = batch, batch, mask, loss_mask\n","            loss = training_loss(net, nn.MSELoss(), X, diffusion_hyperparams,\n","                                 only_generate_missing=only_generate_missing)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            if n_iter % iters_per_logging == 0:\n","                print(\"iteration: {} \\tloss: {}\".format(n_iter, loss.item()))\n","\n","            # save checkpoint\n","            if n_iter > 0 and n_iter % iters_per_ckpt == 0:\n","                checkpoint_name = '{}.pkl'.format(n_iter)\n","                torch.save({'model_state_dict': net.state_dict(),\n","                            'optimizer_state_dict': optimizer.state_dict()},\n","                           os.path.join(output_directory, checkpoint_name))\n","                print('model at iteration %s is saved' % n_iter)\n","\n","            n_iter += 1\n","\n","   "],"metadata":{"id":"-t0qKUmfaGu6","executionInfo":{"status":"ok","timestamp":1668879363935,"user_tz":0,"elapsed":234,"user":{"displayName":"Zihao LIU","userId":"01384449044500819690"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('-c', '--config', type=str, default='/content/drive/MyDrive/JPMorgan/自写代码/Pytorch_codes/config/config_SSSDS4.json',  \n","                        help='JSON file for configuration')\n","\n","    args = parser.parse_args(\"\")\n","\n","    with open(args.config) as f:\n","        data = f.read()\n","\n","    config = json.loads(data)\n","    print(config)\n","\n","    train_config = config[\"train_config\"]  # training parameters\n","\n","    global trainset_config\n","    trainset_config = config[\"trainset_config\"]  # to load trainset\n","\n","    global diffusion_config\n","    diffusion_config = config[\"diffusion_config\"]  # basic hyperparameters\n","\n","    global diffusion_hyperparams\n","    diffusion_hyperparams = calc_diffusion_hyperparams(\n","        **diffusion_config)  # dictionary of all diffusion hyperparameters\n","\n","    global model_config\n","    if train_config['use_model'] == 0:\n","        model_config = config['wavenet_config']\n","    elif train_config['use_model'] == 1:\n","        model_config = config['sashimi_config']\n","    elif train_config['use_model'] == 2:\n","        model_config = config['wavenet_config']\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FddY4GWp3xt_","executionInfo":{"status":"ok","timestamp":1668879367681,"user_tz":0,"elapsed":194,"user":{"displayName":"Zihao LIU","userId":"01384449044500819690"}},"outputId":"c9318c1b-b55e-48cd-834f-cb474c3b9f43"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["{'diffusion_config': {'T': 200, 'beta_0': 0.0001, 'beta_T': 0.02}, 'wavenet_config': {'in_channels': 14, 'out_channels': 14, 'num_res_layers': 36, 'res_channels': 256, 'skip_channels': 256, 'diffusion_step_embed_dim_in': 128, 'diffusion_step_embed_dim_mid': 512, 'diffusion_step_embed_dim_out': 512, 's4_lmax': 100, 's4_d_state': 64, 's4_dropout': 0.0, 's4_bidirectional': 1, 's4_layernorm': 1}, 'train_config': {'output_directory': '/content/drive/MyDrive/JPMorgan/自写代码/Pytorch_codes/Results_SSSDS4/Mujoco/train_90', 'ckpt_iter': 'max', 'iters_per_ckpt': 100, 'iters_per_logging': 100, 'n_iters': 500, 'learning_rate': 0.0002, 'only_generate_missing': 1, 'use_model': 2, 'masking': 'rm', 'missing_k': 90}, 'trainset_config': {'train_data_path': '/content/drive/MyDrive/JPMorgan/自写代码/Data/Mujoco/train_mujoco.npy', 'test_data_path': '/content/drive/MyDrive/JPMorgan/自写代码/Data/Mujoco/test_mujoco.npy', 'segment_length': 100, 'sampling_rate': 100}, 'gen_config': {'output_directory': '/content/drive/MyDrive/JPMorgan/自写代码/Pytorch_codes/Results_SSSDS4/Mujoco/test_90', 'ckpt_path': '/content/drive/MyDrive/JPMorgan/自写代码/Pytorch_codes/Results_SSSDS4/Mujoco/test_90'}}\n"]}]},{"cell_type":"code","source":["# The start of the training.\n","# All the parameters are the already set ones in **train_config, it is from the json file we set, \n","# here is \"/content/drive/MyDrive/JPMorgan/自写代码/Pytorch_codes/config/config_SSSDS4.json\",\n","# the \"**\" means the \"train\" model will accept all the parameters in the json file above. So by this way,\n","# all the already defined parameters in the json file will by inputted into the \"train\" model \n","\n","# It will take lots of time when you first run it as it will generate the iteration saving checkpoint. So next\n","# time when you run it, it will just start from the last iteration memory checkpoint. The path you can find is\n","# in the json file called: \"output_directory\"\n","\n","train(**train_config)"],"metadata":{"id":"a176XBiv4yqS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668879732899,"user_tz":0,"elapsed":20396,"user":{"displayName":"Zihao LIU","userId":"01384449044500819690"}},"outputId":"1b38b490-8196-4a1e-b4d1-0d6ffdc45cb3"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["output directory /content/drive/MyDrive/JPMorgan/自写代码/Pytorch_codes/Results_SSSDS4/Mujoco/train_90/T200_beta00.0001_betaT0.02\n","SSSDS4Imputer Parameters: 48.371726M\n","Successfully loaded model at iteration 600\n","Data loaded\n"]}]},{"cell_type":"code","source":["aaa = train(**train_config)"],"metadata":{"id":"fXZO93Bk4ytB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668795642681,"user_tz":0,"elapsed":18952,"user":{"displayName":"Zihao LIU","userId":"01384449044500819690"}},"outputId":"7407e8f5-510f-489f-aaee-2d0a4174cf43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["output directory ./results/mujoco/90/T200_beta00.0001_betaT0.02\n","SSSDS4Imputer Parameters: 48.371726M\n","Successfully loaded model at iteration 600\n","Data loaded\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"EN1PPh9f4y2a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"d0CFLHGJ4y4_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"E_w_NwWg4y7m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"HyluzmfJpld7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668792214586,"user_tz":0,"elapsed":472,"user":{"displayName":"Zihao LIU","userId":"01384449044500819690"}},"outputId":"a2b2a816-926e-4d8e-8afb-4bae9c814465"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Nov 18 17:23:34 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   55C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["torch.cuda.is_available()\n"],"metadata":{"id":"DgjFqSXq3Umu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668794555987,"user_tz":0,"elapsed":517,"user":{"displayName":"Zihao LIU","userId":"01384449044500819690"}},"outputId":"82bea123-e3ee-4da8-96e4-f2db02d1bf7b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":[],"metadata":{"id":"eWrWbQK04eYm"},"execution_count":null,"outputs":[]}]}